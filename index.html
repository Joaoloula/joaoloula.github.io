<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="seal_icon.png">
  <title>João Loula</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>João Loula</name>
        </p>
        <p>I am a second year PhD student in Brain and Cognitive Sciences at MIT advised by <a href="http://web.mit.edu/cocosci/josh.html">Josh Tenenbaum</a>, working at the intersection of robotics and developmental psychology.        </p>
        <p>
          Previously, I was a research intern at <a href="https://research.fb.com/category/facebook-ai-research/">Facebook AI Research</a>, working with <a href="https://cims.nyu.edu/~brenden/">Brenden Lake</a> and <a href="https://research.fb.com/people/baroni-marco/">Marco Baroni</a>, 
          at Harvard with <a href="http://gershmanlab.webfactional.com/people/sam.html"/>Sam Gershman</a>, and at the <a href="https://team.inria.fr/parietal/">Inria Parietal team</a> with <a href="https://team.inria.fr/parietal/team-members/bertrand-thirions-page/">Bertrand Thirion</a> and <a href="http://gael-varoquaux.info/">Gaël Varoquaux</a>.
          I've studied at <a href="http://math.ens-paris-saclay.fr/version-francaise/formations/master-mva/">École Normale Supérieure Paris-Saclay</a>, <a href="https://www.polytechnique.edu/en">École Polytechnique</a> and <a href="http://www5.usp.br/english/?lang=en">Universidade de São Paulo</a>.
        </p>
        <p align=center>
          <a href="mailto:jloula@mit.edu.edu">Email</a> &nbsp/&nbsp
          <a href="JoaoLoula-CV.pdf">CV</a> &nbsp/&nbsp
          <a href="https://scholar.google.ca/citations?user=eqHX3QwAAAAJ&hl=en"> Google Scholar </a> &nbsp/&nbsp
          <a href="https://github.com/Joaoloula"> Github </a>
        </p>
        </td>
        <td width="33%">
        <img src="JoaoLoula.jpg">
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p>
          My work focuses on how children's rich theories of the world and sophisticated mental simulations are used to support action.
          Key areas of interest include planning, tool use, and spatial reasoning.
          </p>

        </td>
      </tr>
      </table>


  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

    <tr onmouseout="corl2020_stop()" onmouseover="corl2020_start()" >
      <td width="45%">

        <img src="decoding.png" width="350px" height="215px" />
      </td>
      <td valign="top" width="55%">
        <p>
	  <a href="Arxiv__Inference_and_Planning_with_Virtual_and_Physical_Constraints_for_Object_Manipulation.pdf">
            <papertitle>Inference and Planning with Virtual and Physical Constraints for Object Manipulation</papertitle>
	  </a>
	  <br>
    <strong>João Loula</strong>,
    <a href="https://web.mit.edu/krallen/www/">Kelsey Allen</a>,
    <a href="https://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU">Alberto Rodriguez</a>,
    <a href="http://web.mit.edu/cocosci/josh.html">Josh Tenenbaum</a>
    <a href="https://robotics.umich.edu/profile/nima-fazeli/">Nima Fazeli</a>
	<br>Under review <br>
        <p></p>
        <p>
        We propose a framework for manipulation that decomposes tasks
        into kinematic graphs comprised of virtual and physical kinematic constraints. To
        this end, we first infer a set of producible constraints during an exploration phase.
        Next, we demonstrate an efficient planning procedure that uses kinematic graphs
        built from these constraints for object manipulation.
      </td>
    </tr>

    <tr onmouseout="cogsci2020_stop()" onmouseover="cogsci2020_start()" >
      <td width="45%">

        <img src="decoding.png" width="350px" height="215px" />
      </td>
      <td valign="top" width="55%">
        <p>
	  <a href="A_TAMP_Approach_to_the_Development_of_Planning.pdf">
            <papertitle>A Task and Motion Approach to the Development of Planning</papertitle>
	  </a>
	  <br>
    <strong>João Loula</strong>,
    <a href="https://web.mit.edu/krallen/www/">Kelsey Allen</a>,
    <a href="http://web.mit.edu/cocosci/josh.html">Josh Tenenbaum</a>
	   <br>
        <em>CogSci</em>, 2020 <br>
        <p></p>
        <p>
        Developmental psychology presents us with a puzzle: though
        children are remarkably apt at planning their actions, they suf-
        fer from surprising yet consistent shortcomings. We argue that
        these patterns of triumph and failure can be broadly captured
        by the framework of task and motion planning, where plans
        are hybrid entities consisting of both a structured, symbolic
        skeleton and a continuous, low-level trajectory.
      </td>
    </tr>

   <tr onmouseout="iros2020_stop()" onmouseover="iros2020_start()" >
      <td width="45%">

        <img src="decoding.png" width="350px" height="215px" />
      </td>
      <td valign="top" width="55%">
        <p>
	  <a href="Learning_Constraint_based_Planning_Models_From_Demonstrations.pdf">
            <papertitle>Learning constraint-based planning models from demonstrations</papertitle>
	  </a>
	  <br>
    <strong>João Loula</strong>,
    <a href="https://web.mit.edu/krallen/www/">Kelsey Allen</a>,
    <a href="http://web.mit.edu/cocosci/josh.html">Josh Tenenbaum</a>
	   <br>
        <em>IROS</em>, 2020 <br>
        <p></p>
        <p>
        We present a framework for learning constraint-based task
        and motion planning models using gradient descent. Our model
        observes expert demonstrations of a task and decomposes them
        into modes—segments which specify a set of constraints on
        a trajectory optimization problem.
      </td>
    </tr>

    <tr onmouseout="cogsci2019_stop()" onmouseover="cogsci2019_start()" >
      <td width="45%">

        <img src="decoding.png" width="350px" height="215px" />
      </td>
      <td valign="top" width="55%">
        <p>
	  <a href="Discovering_a_Symbolic_Planning_Language_From_Continuous_Experience.pdf">
            <papertitle>Discovering a symbolic planning language from continuous experience</papertitle>
	  </a>
	  <br>
    <strong>João Loula</strong>,
    <a href="https://web.mit.edu/krallen/www/">Kelsey Allen</a>,
    <a href="http://web.mit.edu/tslvr/www/">Tom Silver</a>,
    <a href="http://web.mit.edu/cocosci/josh.html">Josh Tenenbaum</a>
	   <br>
        <em>CogSci</em>, 2019 <br>
        <p></p>
        <p>
        We present a model that starts out with a language
        of low-level physical constraints and, by observing expert
        demonstrations, builds up a library of high-level concepts that
        afford planning and action understanding.
      </td>
    </tr>


    <tr onmouseout="vgdl_stop()" onmouseover="vgdl_start()" >
      <td width="45%">
        <div class="one">
        <div class="two" id = 'vgdl_image'><img src='vgdl_before.png'></div>
        <img src='vgdl_after.png'>
        </div>
        <script type="text/javascript">
        function vgdl_start() {
        document.getElementById('vgdl_image').style.opacity = "1";
        }
        function vgdl_stop() {
        document.getElementById('vgdl_image').style.opacity = "0";
        }
        vgdl_stop()
        </script>
      </td>
      <td valign="top" width="55%">
        <p>
            <papertitle>Human Learning of Video Games</papertitle>
	  <br>
    <a href="https://cbmm.mit.edu/about/people/tsividis">Pedro Tsividis</a>,
    <strong>João Loula</strong>,
    <a href="https://github.com/jrburga">Jake Burga</a>,
    <a href="http://gershmanlab.webfactional.com/people/thomas.html">Thomas Pouncy</a>,
    <a href="http://gershmanlab.webfactional.com/people/sam.html"/>Sam Gershman</a>,
    <a href="http://web.mit.edu/cocosci/josh.html">Josh Tenenbaum</a>
	   <br>
        <em>NIPS Workshop on Cognitively Informed Artificial Intelligence (Spotlight Talk)</em>, 2017 <br>
        <p></p>
        <p> Work on human-level learning in Atari-like games, learning theories from gameplay and using them to plan in a model-based manner. </p>
      </td>
    </tr>

    <tr onmouseout="decoding_stop()" onmouseover="decoding_start()" >
      <td width="45%">
        <img src="decoding.png" width="350px" height="215px" />
      </td>
      <td valign="top" width="55%">
        <p>
	  <a href="https://www.sciencedirect.com/science/article/pii/S1053811917306651">
            <papertitle>Decoding fMRI activity in the time domain improves classification performance</papertitle>
	  </a>
	  <br>
    <strong>João Loula</strong>,
    <a href="http://gael-varoquaux.info/">Gaël Varoquaux</a>,
    <a href="https://team.inria.fr/parietal/team-members/bertrand-thirions-page/">Bertrand Thirion</a>
	   <br>
        <em>NeuroImage</em>, 2017 <br>
        <p></p>
        <p> We show that fMRI decoding can be cast as a regression problem: fitting a design matrix with BOLD activation:
          event classification is then easily obtained from the predicted design matrices.
          Our experiments show this approach outperforms state of the art solutions, especially for designs with low inter-stimulus intervals,
          and the two-step nature of the model brings time-domain interpretability. </p>
      </td>
    </tr>

    <tr onmouseout="nilearn_stop()" onmouseover="nilearn_start()" >
      <td width="45%">
        <div class="one">
        <div class="two" id = 'nilearn_image'><img src='nilearn_surface_small.png'></div>
        <img src='nilearn_surface_small.png'>
        </div>
        <script type="text/javascript">
        function nilearn_start() {
        document.getElementById('nilearn_image').style.opacity = "1";
        }
        function nilearn_stop() {
        document.getElementById('nilearn_image').style.opacity = "0";
        }
        nilearn_stop()
        </script>
      </td>
      <td valign="top" width="55%">
        <p><a href="https://riojournal.com/articles.php?id=12342">
        <papertitle>Loading and plotting of cortical surface representations in Nilearn</papertitle></a><br>
          <a href="https://scholar.google.de/citations?user=72h1BggAAAAJ&hl=en">Julia Huntenburg</a>,
          <a href="https://scholar.google.fr/citations?user=__-U_CcAAAAJ&hl=fr">Alexandre Abraham</a>,
          <strong>João Loula</strong>,
          <a href="https://scholar.google.ch/citations?user=hKz1kQoAAAAJ&hl=de">Franziskus Liem</a>,
          <a href="http://dblp.uni-trier.de/pers/hd/d/Dadi:Kamalaker">Kamalaker Dadi</a>,
          <a href="http://gael-varoquaux.info/">Gaël Varoquaux</a>
          <br>
        <em>Research Ideas and Operations</em>, 2017 <br>
        <p></p>
        <p>We present an initial support of cortical surfaces in Python within the neuroimaging data processing toolbox Nilearn.
          We provide loading and plotting functions for different surface data formats with minimal dependencies, along with examples of their application.
          Limitations of the current implementation and potential next steps are discussed.</p>
      </td>
    </tr>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
      <td>
      <br>
      <p align="right">
        <font size="2">
        <a href="https://jonbarron.info/">website template credit</a>
    </font>
      </p>
      </td>
    </tr>
    </table>
      <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-7580334-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
    </td>
    </tr>
  </table>
  </body>
</html>
