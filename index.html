<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="seal_icon.png">
  <title>João Loula</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>João Loula</name>
        </p>
        <p>I am a PhD student at MIT advised by <a href="http://probcomp.csail.mit.edu/principal-investigator/">Vikash Mansinghka</a>, <a href="http://web.mit.edu/cocosci/josh.html">Josh Tenenbaum</a>, and <a href="https://todonnell.github.io/">Tim O'Donnell</a> working on scaling data science through probabilistic programming.</p>
        <p>
          Previously, I was a research intern at <a href="https://ai.meta.com/research/">Meta AI Research</a>, working with <a href="https://cims.nyu.edu/~brenden/">Brenden Lake</a> and <a href="https://research.fb.com/people/baroni-marco/">Marco Baroni</a>, 
          at Harvard with <a href="http://gershmanlab.webfactional.com/people/sam.html"/>Sam Gershman</a>, and at the <a href="https://team.inria.fr/parietal/">Inria Parietal team</a> with <a href="https://team.inria.fr/parietal/team-members/bertrand-thirions-page/">Bertrand Thirion</a> and <a href="http://gael-varoquaux.info/">Gaël Varoquaux</a>.
          I've studied at <a href="http://math.ens-paris-saclay.fr/version-francaise/formations/master-mva/">École Normale Supérieure Paris-Saclay</a>, <a href="https://www.polytechnique.edu/en">École Polytechnique</a> and <a href="http://www5.usp.br/english/?lang=en">Universidade de São Paulo</a>.
        </p>
        <p align=center>
          <a href="mailto:jloula@mit.edu.edu">Email</a> &nbsp/&nbsp
          <a href="JoaoLoula-CV.pdf">CV</a> &nbsp/&nbsp
          <a href="https://scholar.google.ca/citations?user=eqHX3QwAAAAJ&hl=en"> Google Scholar </a> &nbsp/&nbsp
          <a href="https://github.com/Joaoloula"> Github </a>
        </p>
        </td>
        <td width="33%">
        <img src="JoaoLoula.jpg">
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p>
            Data science typically involves analyzing structured tables and unstructured text to make predictions, impute missing data, discover relationships between variables, infer causal effects, or detect anomalies.
            My work uses probabilistic programming to learn and query generative models for data science, such as guiding transformers to convert unstructured text into structured data, and learning GPU-efficient
            generative models for tables that can solve a wide range of data science tasks.
          </p>

        </td>
      </tr>
      </table>


  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

    <tr onmouseout="iclr2025_stop()" onmouseover="iclr2025_start()" >
      <td width="45%">

        <img src="genparse_main_figure.png" width="350px" height="215px" />
      </td>
      <td valign="top" width="55%">
        <p>
	  <a href="https://openreview.net/forum?id=xoXn62FzD0">
            <papertitle>Syntactic and Semantic Control of Large Language Models via Sequential Monte Carlo</papertitle>
	  </a>
	  <br>
    <strong>João Loula</strong>,
    João Loula, Benjamin LeBrun, Li Du, Ben Lipkin, Clemente Pasti, Gabriel Grand, Tianyu Liu, Yahya Emara, Marjorie Freedman, Jason Eisner, Ryan Cotterell, Vikash Mansinghka, Alexander K. Lew, Tim Vieira, Timothy J. O'Donnell
	   <br>
        <em>ICLR</em>, 2025 <strong>(Oral, <1.8% of papers)</strong> <br>
        <p></p>
        <p>
          A wide range of LLM applications require generating text that conforms to syntactic or semantic constraints. Imposing such constraints nontrivially alters the distribution over sequences, usually making exact sampling intractable. In this work, building on the Language Model Probabilistic Programming framework of Lew et al. (2023), we develop an approach to approximate inference for controlled LLM generation based on sequential Monte Carlo (SMC). Our SMC framework allows us to flexibly incorporate domain- and problem-specific constraints at inference time, and efficiently reallocate computation in light of new information during the course of generation. We demonstrate that our approach improves downstream performance on four challenging domains---Python code generation for data science, text-to-SQL, goal inference, and molecule synthesis. We compare to a number of alternative and ablated approaches, showing that our accuracy improvements are driven by better approximation to the full Bayesian posterior.
      </td>
    </tr>

    <tr onmouseout="under_review_stop()" onmouseover="under_review_start()" >
      <td width="45%">

        <img src="multi_categorical.png" width="350px" height="215px" />
      </td>
      <td valign="top" width="55%">
        <p>
	  <!-- <a href="pdf"> -->
        <papertitle>Scalable tabular data modeling via GPU-accelerated probabilistic programming</papertitle>
	  <!-- </a> -->
	  <br>
    <strong>João Loula</strong>, Ulrich Schaechtle, Josh Tenenbaum, Tim O'Donnell, Vikash Mansinghka
    <!-- <a href="https://web.mit.edu/krallen/www/">Kelsey Allen</a>, -->
    <!-- <a href="http://web.mit.edu/cocosci/josh.html">Josh Tenenbaum</a> -->
	   <br>
        <em>Working Paper</em>, 2025 <br>
        <p></p>
        <p>
          We present GenJaxMix, a mixture of experts generative model for tabular data that can be trained efficiently, via a novel GPU-based sequential Monte Carlo algorithm, as well as queried efficiently, via dedicated GPU implementations of sampling, conditioning, likelihood, and marginalization, whose combination can express a wide range of downstream tasks.
          Through empirical evaluations, we show that GenJaxMix generates more accurate synthetic data than generative models based on diffusion models, transformers, and random forests, while being faster to train. 
          We likewise show that it can perform downstream tasks, such as conditional synthetic data generation, anomaly detection, multiple imputation, and relationship discovery, better than commonly used methods, while being much more query-time efficient. 
      </td>
    </tr>

    <tr onmouseout="icml2024_stop()" onmouseover="icml2024_start()" >
      <td width="45%">

        <img src="fig1_new.png" width="350px" height="215px" />
      </td>
      <td valign="top" width="55%">
        <p>
	  <a href="https://openreview.net/forum?id=Sm1KnFlx0H&referrer=%5Bthe%20profile%20of%20João%20Loula%5D(%2Fprofile%3Fid%3D~João_Loula1)">
            <papertitle>Learning Generative Population Models From Multiple Clinical Datasets Via Probabilistic Programming</papertitle>
	  </a>
	  <br>
    <strong>João Loula</strong>,
    Katherine M. Collins, Ulrich Schaechtle, Joshua B. Tenenbaum, Adrian Weller, Feras Saad, Timothy J. O'Donnell, Vikash Mansinghka
	   <br>
        <em>ICML AccMLBio</em>, 2024 <br>
        <p></p>
        <p>
        Accurate, efficient generative models of clinical populations could accelerate clinical research and improve patient outcomes. For example, such models could infer probable treatment outcomes for different subpopulations, generate high-fidelity synthetic data that can be shared across organizational boundaries, and discover new relationships among clinical variables. Using Bayesian structure learning, we show that it is possible to learn probabilistic program models of clinical populations by combining data from multiple, sparsely overlapping clinical datasets. Through experiments with multiple clinical trials and real-world evidence from census health surveys, we show that our model generates higher quality synthetic data than neural network baselines, supports more accurate inferences across datasets than traditional statistical methods, and can be queried more efficiently than both, opening up new avenues for accessible and efficient AI assistance in clinical research.
      </td>
    </tr>

    <tr onmouseout="cogsci2020_stop()" onmouseover="cogsci2020_start()" >
      <td width="45%">

        <img src="loula_cogsci2020_landscape.gif" width="350px" height="215px" />
      </td>
      <td valign="top" width="55%">
        <p>
	  <a href="A_TAMP_Approach_to_the_Development_of_Planning.pdf">
            <papertitle>A Task and Motion Approach to the Development of Planning</papertitle>
	  </a>
	  <br>
    <strong>João Loula</strong>,
    <a href="https://web.mit.edu/krallen/www/">Kelsey Allen</a>,
    <a href="http://web.mit.edu/cocosci/josh.html">Josh Tenenbaum</a>
	   <br>
        <em>CogSci</em>, 2020 <br>
        <p></p>
        <p>
        Developmental psychology presents us with a puzzle: though
        children are remarkably apt at planning their actions, they suf-
        fer from surprising yet consistent shortcomings. We argue that
        these patterns of triumph and failure can be broadly captured
        by the framework of task and motion planning, where plans
        are hybrid entities consisting of both a structured, symbolic
        skeleton and a continuous, low-level trajectory.
      </td>
    </tr>

   <tr onmouseout="iros2020_stop()" onmouseover="iros2020_start()" >
      <td width="45%">

        <img src="iros2020.jpg" width="350px" height="215px" />
      </td>
      <td valign="top" width="55%">
        <p>
	  <a href="Learning_Constraint_based_Planning_Models_From_Demonstrations.pdf">
            <papertitle>Learning constraint-based planning models from demonstrations</papertitle>
	  </a>
	  <br>
    <strong>João Loula</strong>,
    <a href="https://web.mit.edu/krallen/www/">Kelsey Allen</a>,
    <a href="http://web.mit.edu/tslvr/www/">Tom Silver</a>,
    <a href="http://web.mit.edu/cocosci/josh.html">Josh Tenenbaum</a>
	   <br>
        <em>IROS</em>, 2020 <br>
        <p></p>
        <p>
        We present a framework for learning constraint-based task
        and motion planning models using gradient descent. Our model
        observes expert demonstrations of a task and decomposes them
        into modes—segments which specify a set of constraints on
        a trajectory optimization problem.
      </td>
    </tr>

    <tr onmouseout="cogsci2019_stop()" onmouseover="cogsci2019_start()" >
      <td width="45%">

        <img src="pick_barrier_pick_train.png" width="350px" height="215px" />
      </td>
      <td valign="top" width="55%">
        <p>
	  <a href="Discovering_a_Symbolic_Planning_Language_From_Continuous_Experience.pdf">
            <papertitle>Discovering a symbolic planning language from continuous experience</papertitle>
	  </a>
	  <br>
    <strong>João Loula</strong>,
    <a href="http://web.mit.edu/tslvr/www/">Tom Silver</a>,
    <a href="https://web.mit.edu/krallen/www/">Kelsey Allen</a>,
    <a href="http://web.mit.edu/cocosci/josh.html">Josh Tenenbaum</a>
	   <br>
        <em>CogSci</em>, 2019 <br>
        <p></p>
        <p>
        We present a model that starts out with a language
        of low-level physical constraints and, by observing expert
        demonstrations, builds up a library of high-level concepts that
        afford planning and action understanding.
      </td>
    </tr>

    <tr onmouseout="compositional2018_stop()" onmouseover="compositional2018_start()" >
      <td width="45%">

        <img src="fig_rnn_example.jpg" width="350px" height="180px" />
      </td>
      <td valign="top" width="55%">
        <p>
	  <a href="rearranging_the_familiar.pdf">
            <papertitle>Rearranging the Familiar: Testing Compositional Generalization in
Recurrent Networks</papertitle>
	  </a>
	  <br>
    <strong>João Loula</strong>,
    <a href="https://marcobaroni.org/">Marco Baroni</a>,
    <a href="https://cims.nyu.edu/~brenden/">Brenden Lake</a>,
	   <br>
        <em>EMNLP BlackboxNLP Workshop</em>, 2018 <br>
        <p></p>
        <p>
        We extend the study of systematic compositionality in seq2seq models
        to settings where the model needs only to recombine well-trained functional words.
        Our findings confirm and strengthen the earlier ones: seq2seq models can be impressively good at generalizing to novel combinations of previously-seen input, but only when
        they receive extensive training on the specific
        pattern to be generalized
      </td>
    </tr>


    <tr onmouseout="vgdl_stop()" onmouseover="vgdl_start()" >
      <td width="45%">
        <div class="one">
        <div class="two" id = 'vgdl_image'><img src='vgdl_before.png'></div>
        <img src='vgdl_after.png'>
        </div>
        <script type="text/javascript">
        function vgdl_start() {
        document.getElementById('vgdl_image').style.opacity = "1";
        }
        function vgdl_stop() {
        document.getElementById('vgdl_image').style.opacity = "0";
        }
        vgdl_stop()
        </script>
      </td>
      <td valign="top" width="55%">
        <p>
            <papertitle>Human Learning of Video Games</papertitle>
	  <br>
    <a href="https://cbmm.mit.edu/about/people/tsividis">Pedro Tsividis</a>,
    <strong>João Loula</strong>,
    <a href="https://github.com/jrburga">Jake Burga</a>,
    <a href="http://gershmanlab.webfactional.com/people/thomas.html">Thomas Pouncy</a>,
    <a href="http://gershmanlab.webfactional.com/people/sam.html"/>Sam Gershman</a>,
    <a href="http://web.mit.edu/cocosci/josh.html">Josh Tenenbaum</a>
	   <br>
        <em>NIPS Workshop on Cognitively Informed Artificial Intelligence (Spotlight Talk)</em>, 2017 <br>
        <p></p>
        <p> Work on human-level learning in Atari-like games, learning theories from gameplay and using them to plan in a model-based manner. </p>
      </td>
    </tr>

    <tr onmouseout="decoding_stop()" onmouseover="decoding_start()" >
      <td width="45%">
        <img src="decoding.png" width="350px" height="215px" />
      </td>
      <td valign="top" width="55%">
        <p>
	  <a href="https://www.sciencedirect.com/science/article/pii/S1053811917306651">
            <papertitle>Decoding fMRI activity in the time domain improves classification performance</papertitle>
	  </a>
	  <br>
    <strong>João Loula</strong>,
    <a href="http://gael-varoquaux.info/">Gaël Varoquaux</a>,
    <a href="https://team.inria.fr/parietal/team-members/bertrand-thirions-page/">Bertrand Thirion</a>
	   <br>
        <em>NeuroImage</em>, 2017 <br>
        <p></p>
        <p> We show that fMRI decoding can be cast as a regression problem: fitting a design matrix with BOLD activation:
          event classification is then easily obtained from the predicted design matrices.
          Our experiments show this approach outperforms state of the art solutions, especially for designs with low inter-stimulus intervals,
          and the two-step nature of the model brings time-domain interpretability. </p>
      </td>
    </tr>

    <tr onmouseout="nilearn_stop()" onmouseover="nilearn_start()" >
      <td width="45%">
        <div class="one">
        <div class="two" id = 'nilearn_image'><img src='nilearn_surface_small.png'></div>
        <img src='nilearn_surface_small.png'>
        </div>
        <script type="text/javascript">
        function nilearn_start() {
        document.getElementById('nilearn_image').style.opacity = "1";
        }
        function nilearn_stop() {
        document.getElementById('nilearn_image').style.opacity = "0";
        }
        nilearn_stop()
        </script>
      </td>
      <td valign="top" width="55%">
        <p><a href="https://riojournal.com/articles.php?id=12342">
        <papertitle>Loading and plotting of cortical surface representations in Nilearn</papertitle></a><br>
          <a href="https://scholar.google.de/citations?user=72h1BggAAAAJ&hl=en">Julia Huntenburg</a>,
          <a href="https://scholar.google.fr/citations?user=__-U_CcAAAAJ&hl=fr">Alexandre Abraham</a>,
          <strong>João Loula</strong>,
          <a href="https://scholar.google.ch/citations?user=hKz1kQoAAAAJ&hl=de">Franziskus Liem</a>,
          <a href="http://dblp.uni-trier.de/pers/hd/d/Dadi:Kamalaker">Kamalaker Dadi</a>,
          <a href="http://gael-varoquaux.info/">Gaël Varoquaux</a>
          <br>
        <em>Research Ideas and Operations</em>, 2017 <br>
        <p></p>
        <p>We present an initial support of cortical surfaces in Python within the neuroimaging data processing toolbox Nilearn.
          We provide loading and plotting functions for different surface data formats with minimal dependencies, along with examples of their application.
          Limitations of the current implementation and potential next steps are discussed.</p>
      </td>
    </tr>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
      <td>
      <br>
      <p align="right">
        <font size="2">
        <a href="https://jonbarron.info/">website template credit</a>
    </font>
      </p>
      </td>
    </tr>
    </table>
      <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-7580334-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
    </td>
    </tr>
  </table>
  </body>
</html>
